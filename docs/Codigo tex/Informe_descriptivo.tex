\documentclass[12pt,a4paper]{article}
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{float}
\usepackage{geometry}
\usepackage{xcolor}
\usepackage{array}
\usepackage{longtable}
\usepackage{chngcntr}
\counterwithin{figure}{section}
\counterwithin{table}{section}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{adjustbox}

\geometry{margin=2.5cm}

% Definimos el color de los meses y líneas
\definecolor{mescolor}{HTML}{024d50}
\definecolor{linecolor}{HTML}{024d50}
\definecolor{verdeagua}{HTML}{1B9E96}
\definecolor{verdeoscuro}{HTML}{002C2D}
\definecolor{verdemedio}{HTML}{004F4E}

% Cambiar color de secciones
\usepackage{titlesec}
\titleformat{\section}
{\color{mescolor}\normalfont\Large\bfseries}
{}{0pt}{}
\titlespacing*{\section}{0pt}{*2}{*1}

% Línea negra debajo de cada mes
\newcommand{\separador}{\vspace{0.5cm}\noindent\rule{\linewidth}{0.5pt}\vspace{0.5cm}}

% Cambiar color en el índice y tamaño más grande
\usepackage{tocloft}
\renewcommand{\cftsecfont}{\color{mescolor}\bfseries\Large}
\renewcommand{\cftsecpagefont}{\color{mescolor}\bfseries\Large}

% Configuración encabezado y pie de página con líneas de color y largo ajustable
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\textbf{Proyecto BlindAssist}}
\fancyhead[R]{\includegraphics[width=0.08\linewidth]{Informe descriptivo/logo indice.png}} % Espacio vacío para que no haya logo
\fancyfoot[C]{\thepage}

% Línea de encabezado de color y largo personalizado
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

\renewcommand{\headrule}{%
\color{linecolor}\hrule width 1\linewidth height 0.4pt \vskip0pt}
\renewcommand{\footrule}{%
\color{linecolor}\hrule width \linewidth height 0.4pt \vskip0pt}

\begin{document}

\begin{titlepage}
    \begin{center}
    
    % --- Imagen centrada en la parte superior ---
    \vspace*{2cm}
    \includegraphics[width=0.8\textwidth]{Informe descriptivo/logo indice.png}\\[2cm] % <-- cambia la ruta a tu imagen

    % --- Título principal ---
    {\Huge\bfseries Proyecto BlindAssist \\[0.5cm]}
    {\Large Informe Descriptivo}\\[1.5cm]


    % --- Institución o facultad ---
    {\large Escuela de Educación Secundaria Tecnica N°7 "Taller Regional "}\\
    {\large 7°2 Avionica}

    % --- Espacio para dejar limpio el resto de la hoja ---
    \vfill
    \end{center}
\end{titlepage}

% Índice con numeración desde aquí
\setcounter{page}{1}
\setcounter{tocdepth}{4} % muestra hasta paragraph en el índice
\setcounter{secnumdepth}{4}
\tableofcontents
\newpage

%--- Introducción ---
\section{Introducción}

\subsection{Integrantes}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\linewidth]{Informe descriptivo/Fotoramiro.jpg}
\end{figure}
\begin{center}
Castillo Ramiro\\
DNI: 47516171\\
7°2 Avionica
\end{center}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\linewidth]{Informe descriptivo/fotopino.jpg}
\end{figure}
\begin{center}

Pino Octavio\\
DNI: 47882634\\
7°2 Avionica
\end{center}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\linewidth]{Informe descriptivo/Fototiago.jpg}
\end{figure}

\begin{center}
Quattrocchi Tiago\\
DNI: 47510542\\
7°2 Avionica
\end{center}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{Informe descriptivo/Fotogrupo.jpg}
    \caption{Grupo BlindAssist}
\end{figure}

\subsection{Docentes a Cargo}
    \begin{center}
        \begin{itemize}
        \item Argüello Gabriel
        \item Bianco Carlos
        \item Carlassara Fabrizio
        \item Medina Sergio
        \item Palmieri Diego
        \end{itemize}
    \end{center}

\subsection{Desarrollo del proyecto}
\subsubsection*{Fecha de Inicio}
14/4/2025
\subsubsection*{Duración del proyecto}
25 Semanas
\subsubsection*{Esfuerzo del proyecto}
Maximo de 8 horas de trabajo (200 horas de trabajo en todo el año)
\subsubsection*{Lenguajes utilizados}
\begin{itemize}
\item LaTex
\item CSS
\item HTML
\item Python
\item Javascript
\end{itemize}

\subsubsection*{Programas utilizados}

\begin{itemize}
    \item OverLeaf
    \item Visual Studio Code
    \item Github Desktop
    \item Termius
    \item Proteus 8
    \item AutoCad
    \item UltiMaker
    \item Benewake Software
\end{itemize}

\separador

\section{Descripción}

\subsection{Objetivo}
El objetivo de este proyecto es mantener la integridad de las personas ciegas o con algún tipo de discapacidad visual en cualquier tipo de entorno urbano y darles un mayor nivel de conciencia en entornos mas cerrados. Para ello, desarrollamos un dispositivo que mediante reconocimiento por inteligencia artificial y la detección de objetos utilizando tecnología láser para avisar al usuario sobre un obstáculo en frente, por encima de la cadera, la presencia de alguna persona en un espacio cerrado y la cantidad de individuos que se encuentran en el mismo espacio, contando con alertas sonoras y vibratorias que no alteren su percepción y condición actual.Este dispositivo funcionara como una ayuda al bastón que utilizan en su día a día sin modificar su efectividad o tratar de reemplazar su función.

\subsection{Alcance}
\begin{itemize}

\item Cómo objetivo final, querríamos que este este proyecto llegue a ser un prototipo funcional y autónomo, con el menor tamaño posible para la comodidad del usuario. Contar con una IA correctamente entrenada y optimizada en rendimiento, que trabaje en conjunto al área cubierta y sensada por los lasers. Teniendo en cuenta las posibilidades, buscamos que las alertas sensoriales sean claras para el usuario así tiene una experiencia placentera en su día a día.
\end{itemize}

\subsection{Temática}

 \begin{itemize}
 \item Inclusión social: Nuestro proyecto abarca los parámetros presentados en la temática de inclusión social. Esto debido a que el proyecto mismo busca ayudar con el tránsito de las personas con discapacidad tanto en la vía pública cómo lugares cerrados desconocidos. Además, también puede ayudar con su comunicación y vida social, ya que los alerta de las personas que tienen a su alrededor. 
 \end{itemize}
 
\subsection{Problemas a resolver}

\begin{itemize}
\item Obstáculos repentinos en la vía publica, pueden presentar dificultad a la hora de detectar postes, árboles y otros peligros inesperados que se encuentren por encima de su tren inferior (a partir de la cadera), siendo que la mayoría de las veces el rango que cubre el bastón no es suficiente para detectar y avisar efectivamente a la persona con discapacidad visual.
\item El riesgo constante que sufren en la vía publica termina llevando a que dependan mucho de terceros, como puede ser transeúntes que los apoyen o en casos de personas con una edad mas avanzada, un cuidador designado o familiar cercano. Tenemos en cuenta la falta de autonomía que genera esta problemática, la dependencia que terminan teniendo de terceros es una de las problemáticas más importantes a resolver y la idea es darles una herramienta de autonomía e integración.
\item Proteger su intimidad pudiendo detectar personas que están en el mismo espacio cerrado sin depender de que la persona avise de su llegada, también permitiéndoles conocer la ubicación de dichos individuos, dándole un mejor sentido y conciencia situacional.
\end{itemize}

\subsection{Público beneficiado}
El proyecto está destinado a personas con impedimentos visuales. En el mundo hay 2200 millones de personas con visibilidad reducida, 43,3 millones son no videntes. Esta es la demográfica que será beneficiada directamente por el proyecto, habilitando el tránsito por la vía pública de manera más segura y sin problemas que puedan llegar a afectar su integridad o la rehabilitación a la que están sometidos. Además, al ser un accesorio portable, compacto y difícil de perder u olvidar, no interrumpe en las acciones que pueda realizar el usuario en su vida cotidiana. Este proyecto también beneficiará indirectamente a instituciones privadas como seguros de salud y ART (Aseguradoras de Riesgo del Trabajo), ya que estos pueden ofrecerle como una ayuda al grupo de personas antes descritas. También aplica para la vida cotidiana o la vida pública, ya que se reduce el riesgo de accidentes y la carga que supone a los familiares a la hora de ayudarlo.



\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{Informe descriptivo/graf1.png}
    \caption{Tabla de población ciega por continentes.}
\end{figure}

\subsection{Impacto}
 \begin{itemize}
 
\item En un contexto social, este prototipo tiene el potencial de transformar la vida de millones de personas. Como mencionamos anteriormente, más de 40 millones de personas en todo el mundo viven con discapacidad visual. Este impacto no solo afectaría a las personas con esta discapacidad, sino también a sus cuidadores y familiares directos. Es decir, podría beneficiar a una gran cantidad de personas y comunidades. Especialmente en regiones como África, Asia y América del Sur, donde existe un alto número de personas con discapacidad visual, pero donde los recursos y la infraestructura necesarios para facilitar su movilidad y vida cotidiana son limitados.

     
 \end{itemize}

\subsection{Descripción General}

\begin{itemize}

    \item BlindAssist es un proyecto que busca facilitar el tránsito de sus usuarios en la vida cotidiana. A través de un dispositivo colgante que puedan llevar encima mismos o en algún accesorio que mejore su movilidad. Esto lo lograríamos con un conjunto de componentes que trabajan en coordinación. Primero una cámara que detecta elementos específicos, por poner un ejemplo: cestos de basura, señalizaciones, etc. Segundo, unos sensores láser que detectan la proximidad de obstáculos cómo ramas u postes. Cómo tercero, alertas sensoriales a través de audio y vibraciones para alertar al usuario y que este pueda evitar estos inconvenientes.
    
\end{itemize}

\subsection{Funcionalidades}
\begin{itemize}
    \item El dispositivo presenta dos etapas de detección y dos de alerta al usuario. 
    El dispositivo realizará mediciones de distancia mediante los sensores TFmini LIDAR, estos se encuentran dispuestos de tal forma que puedan cubrir varios ángulos en frente de la persona. Acorde a la detección de los sensores, se le comunica al usuario la posición de un objeto intruso en el rango frontal, dependiendo que sensores detectan un objeto a menor distancia que 120cm se realizara un control de potencia de los motores internos, hay dos motores de vibración, uno a la izquierda y derecha del dispositivo, cada uno acorde a los sensores LIDAR de ambos lados, Cuando se detecta algo en el tercer TFmini cambia la organización, ambos motores emitirán la misma potencia, en caso de que el motor frontal y lateral detecten algo dicho lado tendrá un control titilante de la vibración, en caso de que los tres sensores se activen, ambos motores vibran al máximo de potencia.\\
    El sistema de detección basado en Inteligencia Artificial (IA), utiliza la cámara para capturar imágenes continuamente. Un modelo de IA avanzado (YOLOv8) actúa como el cerebro, escaneando cada imagen a alta velocidad para identificar y clasificar objetos relevantes para la seguridad, como personas, autos, bicicletas, camiones y objetos de tropiezo (botellas, etc.). Solo se anuncia un objeto si la IA está lo suficientemente segura de su clasificación (más del 60\% de confianza).
    La comunicación se realiza mediante voz asíncrona. Esta es la clave de la velocidad: el mensaje de voz (``Una persona", "3 autos", "Moto fuera") se envía a un proceso en segundo plano, permitiendo que la cámara y la IA sigan escaneando el entorno sin detenerse ni un instante. Para evitar el ruido constante, un filtro de tiempo de espera (cooldown) asegura que solo se anuncien los cambios de estado (algo nuevo apareció, se fue o cambió de cantidad) y no se repita la misma alerta cada pocos segundos.
    
\end{itemize}

\separador

\section{Hardware}

\subsection{Raspberry Pi 4}
La Raspberry Pi 4 es una computadora de placa única (SBC) compacta y de bajo consumo. A diferencia de las computadoras de escritorio tradicionales, está diseñada para tareas especializadas y prototipado. Utiliza un procesador Broadcom BCM2711 de cuatro núcleos y una arquitectura ARM, lo que la hace ideal para aplicaciones de robótica y automatización. Su funcionamiento se basa en la ejecución de un sistema operativo, como Raspberry Pi OS, que permite programar y controlar los componentes conectados a sus pines de GPIO (General Purpose Input/Output).
\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{Informe descriptivo/Imagen2.png}
\caption{Modulo Raspberry PI 4}
\end{figure}

\subsubsection{PWM}

El PWM (Pulse Width Modulation) en la Raspberry Pi 4 es una técnica digital para generar señales moduladas en ancho de pulso que permiten controlar la potencia aplicada a dispositivos electrónicos.
En este modelo de placa, el PWM puede implementarse tanto por hardware (pines GPIO dedicados) como por software (emulación mediante librerías como RPi.GPIO o pigpio). En este proyecto se aplica para el control de los motores que funcionan como una alerta vibratoria.

\paragraph{Funcionamiento}
El PWM consiste en la generación de una onda cuadrada con dos parámetros principales:

\begin{itemize}
\item Frecuencia (f): cantidad de ciclos por segundo (Hz).

\item Duty cycle (\%): proporción del tiempo en que la señal está en estado alto respecto del periodo total.

La potencia media entregada a la carga es proporcional al duty cycle.
\end{itemize}

\subsubsection{UART}

El UART (Universal Asynchronous Receiver-Transmitter) es un protocolo de comunicación serie asíncrono que transmite y recibe datos bit a bit mediante dos líneas:

\begin{itemize}
    
\item TX (Transmit): envía datos.

\item RX (Receive): recibe datos.

\end{itemize}

\subsection{Raspberry PI CAM V1.3}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{Informe descriptivo/berrycam.png}
    \caption{Raspberry PI CAM V1.3}
\end{figure}

La Raspberry Pi Camera Module v1.3 es una cámara oficial diseñada para las placas Raspberry Pi, basada en el sensor OmniVision OV5647 de 5 megapíxeles. Permite capturar imágenes fijas de hasta 2592×1944 píxeles y grabar video en resoluciones de 1080p a 30 fps, 720p a 60 fps y 480p a 90 fps. Se conecta mediante un cable plano CSI (Camera Serial Interface), lo que asegura una transmisión de datos rápida y optimizada.

Este módulo es compacto y ligero, ideal para visión por computadora, robótica, monitoreo y aplicaciones de IoT. Gracias a su integración directa con la Raspberry Pi y la compatibilidad con librerías como Picamera y OpenCV.

\subsection{TFmini}
El TFmini es un sensor de distancia LiDAR (Light Detection and Ranging). Funciona emitiendo un pulso de láser infrarrojo y midiendo el tiempo que tarda la luz en rebotar en un objeto y regresar al sensor. Esta técnica, conocida como tiempo de vuelo (ToF), le permite calcular la distancia con precisión. Se comunica con la Raspberry Pi a través de interfaces como UART (puerto serie) o I2C, lo que le permite obtener lecturas de distancia de forma rápida y confiable.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{Informe descriptivo/TFmini.png}
    \caption{TFmini S}
\end{figure}

\subsubsection{Descripción General y Principio de Funcionamiento}

El TFmini es un mini módulo LiDAR diseñado para realizar funciones de medición de distancia sin contacto y en tiempo real. Se caracteriza por ofrecer una medición de distancia precisa, estable y de alta velocidad.

El sensor opera bajo el principio de TOF (Time of Flight). El módulo transmite periódicamente una onda de modulación de rayo infrarrojo cercano que se refleja al contactar un objeto. El producto calcula el rango relativo al objeto al medir la diferencia de fase de ida y vuelta (tiempo de vuelo) de la señal.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{Informe descriptivo/principvuelo.png}
    \caption{Principio de tiempo de vuelo}
    \label{fig:placeholder}
\end{figure}

\subsection{Conversor TTL a USB}

El CP2102 es un controlador de puente USB a UART altamente integrado que permite la conversión directa entre interfaces USB y serie. Este dispositivo es ideal para actualizar sistemas que originalmente utilizaban comunicación RS-232, TTL o RS-485, eliminando la necesidad de puertos seriales tradicionales en PCs modernas.  
Gracias a su tamaño compacto y a la mínima cantidad de componentes externos necesarios, el CP2102 ofrece una solución eficiente, confiable y económica para la comunicación entre ordenadores y dispositivos embebidos.
En el caso de este proyecto se utilizara de forma que pueda comunicar la lectura de los tres LIDAR efectivamente teniendo en cuenta la cantidad de salidas USB disponibles por la placa, y que la Raspberry PI 4 presenta únicamente una salida serial por pines.

\begin{figure}[H]
\centering
\includegraphics[width=0.6\linewidth]{Informe descriptivo/Uartransf.png}
\caption{Conversor Serie TTL a USB}
\end{figure}


\subsubsection{Funcionamiento}
El CP2102 actúa como un puente entre la interfaz USB 2.0 y los protocolos UART, RS-232 o RS-485 del dispositivo conectado.  
El chip convierte los datos USB en señales serie y viceversa, facilitando la transmisión y recepción asíncrona de datos.  
El módulo no requiere componentes externos USB y es reconocido automáticamente por la mayoría de los sistemas operativos mediante drivers integrados.

\subsection{Circuito}

\subsubsection{Lista de Componentes}
\begin{longtable}{|>{\raggedright}p{4cm}|c|>{\raggedright\arraybackslash}p{8cm}|}
\hline
\textbf{Componente} & \textbf{Cantidad} & \textbf{Descripción / Función} \\
\hline
Raspberry Pi 4 (J5) & 1 & Microprocesador central, adquisición de datos y control \\
\hline
Sensor TFmini (J1, J2, J3) & 3 & LIDAR para medir distancias \\
\hline
Motores de vibración (J6, J7) & 2 & Generación de señal haptica de alerta \\
\hline
Transistor BC337 (Q1, Q2) & 2 & Etapa de potencia para buzzers \\
\hline
Resistencias 330 $\Omega$ (R1, R2) & 2 & Limitación de corriente en base de transistores \\
\hline
Interruptores (J4, J8) & 2 & Habilitación/deshabilitación manual \\
\hline
Alimentación de baterías (J9, J10) & 2 & Alimentación de la Raspberry Pi 4 y de los motores de vibración)\\
\hline
\caption{Tabla de la lista de componentes del circuito}
\end{longtable}

%--------------------------
\subsubsection{Descripción del circuito}
\begin{enumerate}
    \item Los sensores TFmini (J1, J2, J3) envían datos de distancia vía UART a la Raspberry Pi 4 (J5), dejando como futura posibilidad la comunicacion de UART por software para J2 y J3, teniendo en cuenta que mediante pines unicamente se puede comunicar con J1.
    \item La Raspberry Pi recibe y procesa la información. Si la distancia medida es menor a un umbral, activa una salida GPIO.
    \item El GPIO activa Q1 o Q2 mediante las resistencias R1 y R2.
    \item Los transistores permiten el paso de corriente hacia los motores (J6, J7), que generan la alerta haptica de vibración.
    \item Los interruptores J4 y J8 permiten habilitar/deshabilitar la detección de la IA y seleccionar modos de funcionamiento.
\end{enumerate}

\subsubsection{Esquemático}

\begin{figure}[H]
    \centering
\includegraphics[width=0.8\linewidth]{Informe descriptivo/Captura de pantalla (1).png}
\caption{Esquemático del circuito final}
\end{figure}


\subsubsection{PCB}

\begin{figure}[H]
    \centering
\includegraphics[width=0.8\linewidth]{Informe descriptivo/nuevo PCB.jpg}
\caption{diseño de impresión del circuito}
\end{figure}

\separador

\section{Firmware} 

\subsection{Detección por IA}
El sistema de visión artificial implementado en este proyecto se basa en el modelo de aprendizaje profundo YOLOv8n.pt para la identificación de objetos en tiempo real, utilizando la cámara de la Raspberry Pi como fuente de datos. La arquitectura del software se estructura en un sistema de Programación Orientada a Objetos (POO). Cada componente lógico (cámara, IA, voz, traductor) está encapsulado en una clase dedicada, lo que facilita el desarrollo, las pruebas y el mantenimiento del sistema de manera modular.

\begin{figure}[H]
\noindent\hspace*{-0.7in}% desplaza hacia la izquierda el origen
\includegraphics[width=1.2\linewidth]{Informe descriptivo/diagramaflujoia1.jpg}
\caption{Diagrama de flujo de la detección por IA}
\end{figure}

\subsubsection{logica del bucle continuo}
\begin{itemize}
\item Captura frames de video.
\item Analiza cada frame en busca de objetos.
\item Compara las detecciones con las del frame anterior.
\item Emite una alerta de voz solo cuando se detecta un cambio en el entorno (aparición o desaparición de un objeto).
\end{itemize}

\subsubsection{Arquitectura del Código}
El programa se organiza en un conjunto de clases principales:
\begin{itemize}
\item \textbf{Clase Camara:} Gestiona el hardware de la cámara. Utiliza la librería picamera2 para inicializar y capturar un stream de video en vivo. A diferencia de soluciones de un solo fotograma, esta aproximación optimiza el rendimiento y la tasa de fotogramas por segundo (FPS) al mantener el stream de video abierto.
\item \textbf{Clase IA:} Carga el modelo yolov8n.pt y es responsable de analizar los fotogramas capturados. Identifica objetos en una lista predefinida de clases (clases\_permitidas) y filtra las detecciones por un umbral de confianza (CONFIDENCE\_THRESHOLD), asegurando que solo los objetos relevantes y con alta certeza sean considerados.
\item \textbf{Clase Traductor:} Encapsula el diccionario de traducciones. Su única responsabilidad es convertir los nombres de las clases de YOLO (en inglés, como 'person' o 'car') a sus equivalentes en español, permitiendo que el sistema de voz dé las alertas en el idioma del usuario.
\item \textbf{Clase Voz:} Maneja la síntesis de voz. Para garantizar la fiabilidad del audio, utiliza un método robusto basado en la librería subprocess para ejecutar el comando del sistema espeak y vocalizar las alertas. Esta solución es inmune a los problemas de configuración de audio que se presentan a menudo con otras librerías.
\item \textbf{Clase Main:} Es el punto principal del sistema. Inicializa todas las demás clases y gestiona el bucle de detección en tiempo real. Su lógica más avanzada reside en el método privado \_\_anunciar\_detecciones, que compara las detecciones actuales con las del último ciclo, emitiendo una alerta de voz únicamente cuando se detecta un cambio. Esto evita la repetición constante de las mismas alertas.
\end{itemize}
El sistema se ejecuta continuamente en un bucle while hasta que el usuario lo interrumpe con Ctrl + C. En ese momento, un bloque finally asegura que el hardware de la cámara se detenga de manera segura para evitar fallos del sistema.

\begin{figure}[H]
\noindent\hspace*{-0.7in}% desplaza hacia la izquierda el origen
\includegraphics[width=1.2\linewidth]{Informe descriptivo/Diagramaflujoia2.jpg}
\caption{Diagrama de flujo de clases}
\end{figure}

\subsubsection{Componentes de la Implementación}
\paragraph{Librerías}
\begin{itemize}
\item ultralytics: Se utiliza para cargar y ejecutar el modelo de detección de objetos YOLOv8.
\item picamera2: La interfaz oficial para las cámaras de la Raspberry Pi, proporcionando acceso a un flujo de video de alto rendimiento.
\item cv2 (OpenCV): Se usa para el preprocesamiento de los fotogramas, como la conversión de color necesaria antes de pasarlos al modelo de IA.
\item subprocess: La herramienta estándar de Python para ejecutar comandos del sistema, en este caso, el motor de síntesis de voz espeak.
\item os y sys: Permiten la gestión de archivos y el control del sistema, por ejemplo, para verificar la existencia del modelo YOLO antes de su uso.
\end{itemize}

\paragraph{Manejo de Flujo de Datos}
El flujo de información y la lógica de control se manejan principalmente en el método iniciar() de la clase Main:
\begin{itemize}
\item \textbf{Captura:} self.\_\_camara.capturar\_frame() obtiene una imagen del stream de la cámara.
\item \textbf{Análisis:} El frame se pasa a self.\_\_ia.analizar\_imagen(frame), que devuelve un diccionario con los objetos detectados en el fotograma actual.
\item \textbf{Control de Anuncios:} El diccionario se envía al método \_\_anunciar\_detecciones().
\item \textbf{Reproducción de Audio:} Si hay cambios, la clase Voz es invocada a través de self.\_\_voz.hablar(final\_message).
\end{itemize}
La arquitectura del sistema es muy escalable. Al estar modularizado, se podrían añadir fácilmente nuevas clases sin modificar la lógica central del proyecto.

\subsection{Detección por láser}
\subsubsection{Libreria TFmini}
Esta sección describe el funcionamiento del código implementado para la lectura simultánea de tres sensores LiDAR TFmini conectados a diferentes puertos UART de una Raspberry Pi 4.

El sistema permite:
\begin{itemize}
\item Recepción continua de datos desde los sensores.
\item Procesamiento y almacenamiento de las distancias medidas.
\item Ejecución en paralelo mediante hilos (multithreading).
\item Disponibilidad centralizada de los valores para otras funciones del sistema.
\end{itemize}

\textbf{Descripción General del Sistema:}
El programa se estructura en cuatro bloques principales:
\begin{itemize}
\item Configuración global: Definición de librerías, estructuras de datos y variables compartidas.
\item Módulo de adquisición de datos: Funciones de lectura desde los sensores a través de los puertos UART.
\item Gestión de hilos: Creación de procesos concurrentes para la lectura simultánea.
\item Bucle principal: Supervisión e impresión periódica de los valores capturados.
\end{itemize}
La arquitectura se basa en la comunicación serial estándar (UART) a una velocidad de 115200 baudios, con tramas de 9 bytes emitidas por cada TFmini.

\paragraph{Librerías:}
\begin{itemize}
\item \textbf{serial (pyserial):} Permite abrir, configurar y gestionar la comunicación UART.
\item \textbf{time:} Se utiliza para pausas entre lecturas y evitar sobrecarga del procesador.
\item \textbf{threading:} Facilita la ejecución concurrente de múltiples lecturas de sensores.
\end{itemize}

\paragraph{Estructuras Globales:}
\begin{verbatim}
distancias = {
"uart1": None,
"uart2": None,
"uart3": None,
}
\end{verbatim}
Diccionario que almacena la última distancia válida obtenida de cada sensor. Inicialmente los valores son None y se actualizan en tiempo real. Facilita la consulta de datos desde cualquier parte del programa.

\paragraph{Función Genérica de Adquisición de Datos:}

\begin{verbatim}
def getTFminiData(port, key_name):
ser = serial.Serial(port, 115200, timeout=1)
\end{verbatim}

\textbf{Flujo de la función:} 
Apertura del puerto serie con parámetros: Velocidad de 115200 baudios, timeout de 1 segundo. Bucle infinito de lectura: Verifica si hay al menos 9 bytes disponibles (ser.in\_waiting > 8). Lee un paquete completo (ser.read(9)). Validación de cabecera: Primeros dos bytes deben ser 0x59 0x59. Si no coincide, se descarta la trama. Reconstrucción de la distancia: Byte [2] = parte baja (Low). Byte [3] = parte alta (High). Cálculo: distance = low + (high << 8).

\end{quoting}

\paragraph{Almacenamiento de datos}
La distancia calculada se guarda en el diccionario global bajo la clave correspondiente (uart1, uart2, uart3). Retardo de control time.sleep(0.01) para liberar recursos del procesador.

\paragraph{Funciones Específicas por Puerto UART}

\begin{verbatim}
def getTFminiData_uart1():
getTFminiData("/dev/serial0", "uart1")
\end{verbatim}
Función getTFminiData\_uart1: Llama al puerto /dev/serial0. Función getTFminiData\_uart2: Llama al puerto /dev/ttyUSB1. Función getTFminiData\_uart3: Llama al puerto /dev/ttyUSB2. Estas funciones permiten escalar el sistema sin modificar la lógica principal.

\paragraph{Gestión de Hilos y Ejecución Principal}
\begin{verbatim}
if __name__ == '__main__':
...
\end{verbatim}
Creación de hilos: Cada hilo ejecuta una de las funciones específicas (uart1, uart2, uart3). Se utilizan hilos daemon, lo que asegura que se cierren cuando termine el programa. Ejecución concurrente: Los tres hilos inician en paralelo con .start(). Se garantiza la lectura simultánea de los sensores. Bucle principal de supervisión: Cada segundo imprime las distancias almacenadas en distancias y permite monitorear en consola el funcionamiento del sistema. Interrupción del usuario: Al presionar Ctrl + C, se captura la excepción KeyboardInterrupt. Se muestra un mensaje de salida segura.

\begin{figure}[H]
\noindent\hspace*{-0.7in}% desplaza hacia la izquierda el origen
\includegraphics[width=1.2\linewidth,height=1.1\linewidth]{Informe descriptivo/diagrama de flujo TFmini3.png}
\caption{Diagrama de flujo de la lectura de distancias}
\end{figure}

\subsubsection{Control de Motores}

El código implementa un sistema de control de dos motores mediante modulación por ancho de pulso (PWM) utilizando una Raspberry Pi 4.  
El control se basa en las distancias medidas por tres sensores LiDAR TFmini conectados a los puertos UART de la Raspberry Pi.  
El objetivo del programa es variar la velocidad de los motores en función de la proximidad de obstáculos, generando alertas hapticas (mediante vibraciones) cuando se detectan objetos a menos de 120 cm.


\paragraph{Librerías y Dependencias}

\begin{itemize}
    \item \texttt{time}: Control de tiempos y retardos.
    \item \texttt{threading}: Permite ejecutar lecturas de los tres sensores en paralelo mediante hilos.
    \item \texttt{RPi.GPIO}: Control de los pines GPIO de la Raspberry Pi.
    \item \texttt{TFtest3}: Módulo externo que contiene las funciones de lectura \texttt{getTFminiData\_uart1/2/3} y el diccionario \texttt{distancias}.
\end{itemize}

\paragraph{Configuración del Sistema}

\begin{itemize}
    \item\textbf{Modo GPIO:}

\begin{verbatim}
GPIO.setmode(GPIO.BCM)
\end{verbatim}

\item\textbf{Asignación de Pines PWM:}
\begin{verbatim}
MOTOR_PIN1 = 18
MOTOR_PIN2 = 13
\end{verbatim}

Estos pines son compatibles con PWM por hardware en la Raspberry Pi 4.

\item\textbf{Inicialización de PWM:}
\begin{verbatim}
pwm1 = GPIO.PWM(MOTOR_PIN1, 100)
pwm2 = GPIO.PWM(MOTOR_PIN2, 100)
pwm1.start(0)
pwm2.start(0)
\end{verbatim}

Se inicializan ambas salidas con una frecuencia de \textbf{100 Hz} y un duty cicle del \textbf{0 \%}.
\end{itemize}

\paragraph{Función Auxiliar}
\begin{itemize}
\texttt{calcular\_duty(d):} Esta función traduce la distancia medida (en cm) al porcentaje de ciclo útil del PWM.  
Si el objeto está a menos de \textbf{120 cm}, el duty cycle aumenta proporcionalmente al acercamiento.

\begin{verbatim}
if d < 120:
    return min(100, 120 - d)
\end{verbatim}

Ejemplo de funcionamiento:
\begin{itemize}
    \item Si $d = 100$ cm $\rightarrow$ $duty = 20\%$
    \item Si $d = 50$ cm $\rightarrow$ $duty = 70\%$
\end{itemize}
\end{itemize}

\paragraph{Lógica de Control Principal}
\begin{itemize}

Función central que coordina la lectura de los tres sensores y actualiza los dos motores según las condiciones detectadas.

\textbf{Ciclo de operación:}

\begin{enumerate}
    \item Reinicia el PWM en 0\% al comienzo de cada ciclo.  
    \item Lee las distancias \texttt{d1}, \texttt{d2}, \texttt{d3} desde el diccionario compartido \texttt{distancias}.  
    \item Calcula los valores de duty correspondientes.  
    \item Evalúa las condiciones de proximidad menores a 120 cm.  
\end{enumerate}

\textbf{Casos contemplados:}

\begin{table}[H]
\centering
\begin{tabular}{|c|p{5cm}|p{7cm}|}
\hline
\textbf{Caso} & \textbf{Condición} & \textbf{Acción} \\ \hline
1 & d1 $<$ 120 & Activa PWM1 proporcionalmente. \\ \hline
2 & d2 $<$ 120 & Activa PWM2 proporcionalmente. \\ \hline
3 & d3 $<$ 120 & Ambos motores actúan con el mismo PWM. \\ \hline
4 & d2 y d3 $<$ 120 & Motor 2 titila alternadamente. \\ \hline
5 & d1 y d3 $<$ 120 & Motor 1 titila alternadamente. \\ \hline
6 & d1, d2 y d3 $<$ 120 & Ambos motores al 100\% (alerta crítica). \\ \hline
\end{tabular}
\caption{Casos de control de motores según distancias detectadas.}
\end{table}
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Informe descriptivo/diagrama PWM.png}
    \caption{Diagrama de flujo de la lógica PWM}
\end{figure}

\separador

\section{Diseño}

\subsection*{ Prototipo 3D}

\subsection*{ Materiales Utilizados / Programas}
\begin{itemize}
\item Filamento de impresión 3D PLA.
\item Tornillos 1/8
\item AutoCAD
\end{itemize}

\subsection{Diseño General}
El diseño corresponde a un prototipo de carcasa destinado a integrar de forma eficiente los sensores y componentes del proyecto. Su geometría incluye un frente inclinado en forma triangular, que permite optimizar los ángulos de medición de los LIDAR y ampliar su campo de detección en entornos urbanos. También incorpora un orificio frontal para la cámara y tres ranuras específicas para los LIDAR, lo que asegura una orientación precisa y funcional. El sistema de cierre se resuelve mediante anclajes en el borde del cuerpo y orejas externas para tornillos, lo que garantiza un ajuste firme y facilita el mantenimiento. A nivel general, el prototipo busca maximizar el aprovechamiento del espacio interno, mejorar la disposición de los sensores y proteger los componentes electrónicos. Es importante remarcar que se trata de un prototipo en evolución, sujeto a mejoras tanto en la disposición interna como en la ergonomía y robustez del ensamble.

\subsection{Comparaciones entre Versiones}
\begin{itemize}
\item \textbf{Espacio interno:} El primer prototipo no contaba con el espacio suficiente para albergar todos los componentes electrónicos. En el segundo, se corrigieron dimensiones y proporciones, logrando una organización más adecuada del volumen interno.
\item \textbf{Ranuras para sensores LIDAR:} En el primer modelo, las ranuras eran más genéricas y no contemplaban bien la orientación de los sensores. El segundo prototipo introdujo tres ranuras específicas para los LIDAR, con un frente inclinado que mejora el ángulo de detección.
\item \textbf{Relieves y fijaciones internas:} El primer y segundo prototipo carecían de soporte interno para los componentes. En el tercer prototipo, que exteriormente mantiene la misma geometría, se añadieron relieves interiores para que los LIDAR queden bien posicionados y se incorporaron finalmente los anclajes para fijar las plaquetas electrónicas, permitiendo un montaje más firme y seguro.
\item Sistema de cierre: Desde el segundo prototipo ya se contemplaban orejas externas para tornillería, pero en el prototipos siguiente se mejoró la definición de los encastres en el borde del cuerpo, logrando un cierre más sólido.
\item La serie de prototipos muestra una mejora constante en la funcionalidad y organización interna de la carcasa. El primer prototipo permitió validar dimensiones generales. El segundo resolvió la correcta orientación de los LIDAR con el frente inclinado y el aumento de espacio. El tercero introdujo finalmente los relieves interiores y fijaciones internas, mejorando la integración de los componentes. Este proceso iterativo confirma que el diseño está en el camino correcto, pero aún con margen para seguir perfeccionando aspectos de robustez estructural, ensamblaje y usabilidad.
\end{itemize}

\subsection{Imágenes}
\subsubsection{Primer Prototipo}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{Informe descriptivo/modelo baj1.png}
    \caption{Primera base}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{Informe descriptivo/primer tapa.png}
    \caption{Primera tapa}
\end{figure}

\subsubsection{Segundo Prototipo}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{Informe descriptivo/segundo proto.png}
    \caption{Tapa y base}
\end{figure}

\separador

\begin{thebibliography}{9}

\subsection{Datasheets y manuales}

\bibitem{raspberrypi4}
\emph{Raspberry pi 4 datasheet:}. \href{https://github.com/impatrq/BLINDSSIST/blob/main/Hardware/raspberry-pi-4-datasheet.pdf}{https://github.com/impatrq/BLINDSSIST/raspberry-pi-4-datasheet.pdf}

\bibitem{raspberry_cam}
Raspberry Pi Foundation. 
\emph{Raspberry Pi Camera Module v1.3 Documentation:}. \href{https://www.raspberrypi.com/documentation/accessories/camera.html}{https://www.raspberrypi.com/documentation/accessories/camera.html}

\bibitem{tfmini_doc}
Benewake. 
\emph{TFmini LiDAR Product Manual:} \href{https://github.com/impatrq/BLINDSSIST/blob/main/Hardware/TFmini/SJ-PM-TFmini-T-01_A06%20Product%20Manual_EN.pdf}{https://github.com/impatrq/BLINDSSIST/SJ-PM-TFmini-T-01_A06}

\bibitem{TFminidatasheet}
\emph{TFmini Lidar Datasheet:}
\href{https://github.com/impatrq/BLINDSSIST/blob/main/Hardware/TFmini/SJ-GU-TFmini-T-01_A05%20Datasheet.pdf}{https://github.com/impatrq/BLINDSSIST/SJ-GU-TFmini-T-01_A05}

\bibitem{convserieausb}
\emph{Conversor serie a usb datasheet:}
\href{https://www.alldatasheet.com/datasheet-pdf/pdf/201067/SILABS/CP2102.html}{https://www.alldatasheet.com/datasheet-pdf/pdf/201067/SILABS/CP2102.html}

\bibitem{fuente}
\emph{Conversor buck step-down datasheet:}
\href{https://www.alldatasheet.com/datasheet-pdf/pdf/1134361/XLSEMI/XL4015.html}{https://www.alldatasheet.com/datasheet-pdf/pdf/1134361/XLSEMI/XL4015.html}

\subsection{Software}

\bibitem{TFmini}
\emph{Lectura de sensor TFmini:}
\href{https://github.com/impatrq/BLINDSSIST/blob/main/firmware/TFmini3.py}{https://github.com/impatrq/BLINDSSIST/TFmini3.py}

\bibitem{ContPWM}
\emph{Control de motores:}
\href{https://github.com/impatrq/BLINDSSIST/blob/main/firmware/TFmini/ContPWM.py}{https://github.com/impatrq/BLINDSSIST/ContPWM.py}

\bibitem{Cam}
\emph{Codigo de deteccion de IA:}
\href{https://github.com/impatrq/BLINDSSIST/blob/main/firmware/main.py}{https://github.com/impatrq/BLINDSSIST/mainPOO.py}

\bibitem{POO}
\emph{Codigo de Python orientado a objetos: }
\href{https://github.com/impatrq/BLINDSSIST/blob/main/firmware/mainPOO.py}{https://github.com/impatrq/BLINDSSIST/mainPOO.py}

\subsection{Pagina web}
\bibitem{Página web}
\emph{Carpeta de Web BlindAssist}
\href{https://github.com/impatrq/BLINDSSIST/tree/main/firmware/pagina%20web}{https://github.com/impatrq/BLINDSSIST/pagina}
\end{thebibliography}

\end{document}